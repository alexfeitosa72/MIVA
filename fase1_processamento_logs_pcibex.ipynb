{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "690d4824",
   "metadata": {},
   "source": [
    "### üîç 1. Setup e Leitura dos Dados\n",
    "---\n",
    "\n",
    "O dataset `MQD-1465` cont√©m 1465 frases coletadas da plataforma \"Meu Querido Di√°rio\" (www.meuqueridodiario.com.br)\n",
    "\n",
    "INPUTS NECESS√ÅRIOS\n",
    "* data/MQD-1465.csv (dataset original)\n",
    "* data/logs_brutos (pasta com os logs brutos do experimento no PCIBex Farm)\n",
    "\n",
    "TRATAMENTO PROPOSTO</br>\n",
    "* Divis√£o do dataset em 10 blocos com no m√°ximo 150 frases</br>\n",
    "* Remo√ß√£o de frases duplicadas no dataset original</br>\n",
    "* Fixa√ßao de seed para reprodutibilidade\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5975c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importa√ß√µes de bibliotecas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d7d62bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RANDOMIZACAO MQD-1465 (Seed: 42)\n",
      "================================================================================\n",
      "\n",
      "[1] Carregando e randomizando dados...\n",
      "    1465 registros carregados\n",
      "    Randomizado com seed 42\n",
      "    Primeiros IDs: [1039, 213, 314, 598, 931]\n",
      "\n",
      "[2] Removendo duplicatas...\n",
      "    Duplicatas encontradas:\n",
      "    - IDs [475, 476]: mantendo 475, removendo [476]\n",
      "    - IDs [952, 953]: mantendo 952, removendo [953]\n",
      "    Total apos remocao: 1463 registros\n",
      "\n",
      "[3] Padronizando frases...\n",
      "    Espacos e aspas removidos\n",
      "\n",
      "[4] Salvando 'data/logs_processados/MQD-1463_random_sem_repeticao.csv'...\n",
      "    Arquivo salvo com sucesso!\n",
      "\n",
      "================================================================================\n",
      "ESTATISTICAS\n",
      "================================================================================\n",
      "\n",
      "Total: 1463 registros\n",
      "\n",
      "Classificacao:\n",
      "  -1:  544 ( 37.2%)\n",
      "   0:  409 ( 28.0%)\n",
      "   1:  510 ( 34.9%)\n",
      "\n",
      "Juizes:\n",
      "  2:  525 ( 35.9%)\n",
      "  3:  936 ( 64.0%)\n",
      "  4:    2 (  0.1%)\n",
      "\n",
      "================================================================================\n",
      "CONCLUIDO!\n",
      "================================================================================\n",
      "\n",
      "Arquivo: data/logs_processados/MQD-1463_random_sem_repeticao.csv (1463 registros)\n",
      "DataFrame 'df_final' disponivel para uso\n",
      "\n",
      "Exemplos de uso:\n",
      "  df_final.head()          # Ver primeiras linhas\n",
      "  df_final.info()          # Informacoes do dataset\n",
      "  df_final.describe()      # Estatisticas\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURACAO\n",
    "# ============================================================================\n",
    "SEED = 42\n",
    "INPUT_FILE = 'data/MQD-1465.csv'\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RANDOMIZACAO MQD-1465 (Seed: 42)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# ETAPA 1: CARREGAR E RANDOMIZAR\n",
    "# ============================================================================\n",
    "print(\"\\n[1] Carregando e randomizando dados...\")\n",
    "\n",
    "df = pd.read_csv(INPUT_FILE, encoding='utf-8')\n",
    "df.columns = ['id', 'frase', 'classificacao', 'juizes']\n",
    "print(f\"    {len(df)} registros carregados\")\n",
    "\n",
    "df_random = df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "print(f\"    Randomizado com seed {SEED}\")\n",
    "print(f\"    Primeiros IDs: {df_random['id'].head(5).tolist()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# ETAPA 2: REMOVER DUPLICATAS\n",
    "# ============================================================================\n",
    "print(\"\\n[2] Removendo duplicatas...\")\n",
    "\n",
    "duplicatas = df_random[df_random.duplicated(subset=['frase'], keep=False)]\n",
    "if len(duplicatas) > 0:\n",
    "    print(f\"    Duplicatas encontradas:\")\n",
    "    for frase, grupo in duplicatas.groupby('frase'):\n",
    "        ids = grupo['id'].tolist()\n",
    "        mantido = df_random[df_random['frase'] == frase]['id'].iloc[0]\n",
    "        removidos = [i for i in ids if i != mantido]\n",
    "        print(f\"    - IDs {ids}: mantendo {mantido}, removendo {removidos}\")\n",
    "\n",
    "df_final = df_random.drop_duplicates(subset=['frase'], keep='first').reset_index(drop=True)\n",
    "print(f\"    Total apos remocao: {len(df_final)} registros\")\n",
    "\n",
    "# ============================================================================\n",
    "# ETAPA 3: PADRONIZAR FRASES\n",
    "# ============================================================================\n",
    "print(\"\\n[3] Padronizando frases...\")\n",
    "\n",
    "df_final['frase'] = df_final['frase'].str.strip().str.replace('\"', '', regex=False)\n",
    "print(f\"    Espacos e aspas removidos\")\n",
    "\n",
    "# ============================================================================\n",
    "# ETAPA 4: SALVAR ARQUIVO\n",
    "# ============================================================================\n",
    "# Define nome do arquivo dinamicamente baseado no numero de registros\n",
    "num_registros = len(df_final)\n",
    "OUTPUT_FILE = f'data/logs_processados/MQD-{num_registros}_random_sem_repeticao.csv'\n",
    "\n",
    "print(f\"\\n[4] Salvando '{OUTPUT_FILE}'...\")\n",
    "\n",
    "# Garante que a pasta de destino exista\n",
    "os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)\n",
    "\n",
    "with open(OUTPUT_FILE, 'w', encoding='utf-8', newline='') as f:\n",
    "    f.write('id\\tfrase\\tclassificacao\\tjuizes\\n')\n",
    "    for _, row in df_final.iterrows():\n",
    "        f.write(f'{row[\"id\"]}\\t\"{row[\"frase\"]}\"\\t{row[\"classificacao\"]}\\t{row[\"juizes\"]}\\n')\n",
    "\n",
    "print(f\"    Arquivo salvo com sucesso!\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ESTATISTICAS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ESTATISTICAS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nTotal: {len(df_final)} registros\\n\")\n",
    "\n",
    "print(\"Classificacao:\")\n",
    "for c in sorted(df_final['classificacao'].unique()):\n",
    "    n = (df_final['classificacao'] == c).sum()\n",
    "    print(f\"  {c:>2}: {n:>4} ({100*n/len(df_final):>5.1f}%)\")\n",
    "\n",
    "print(\"\\nJuizes:\")\n",
    "for j in sorted(df_final['juizes'].unique()):\n",
    "    n = (df_final['juizes'] == j).sum()\n",
    "    print(f\"  {j}: {n:>4} ({100*n/len(df_final):>5.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONCLUIDO!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nArquivo: {OUTPUT_FILE} ({len(df_final)} registros)\")\n",
    "print(f\"DataFrame 'df_final' disponivel para uso\")\n",
    "print(\"\\nExemplos de uso:\")\n",
    "print(\"  df_final.head()          # Ver primeiras linhas\")\n",
    "print(\"  df_final.info()          # Informacoes do dataset\")\n",
    "print(\"  df_final.describe()      # Estatisticas\")\n",
    "\n",
    "# Criar variavel global para uso no notebook\n",
    "df_mqd = df_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eaab65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: data/logs_processados\\MQD-1463_random_sem_repeticao.csv\n",
      "Arquivo processado e salvo em: data/logs_processados/MQD-1463_blocos.csv\n",
      "Total de registros: 1463\n",
      "Total de blocos: 10\n",
      "\n",
      "Primeiras linhas do arquivo processado:\n",
      "   id  id_original                                              frase  bloco\n",
      "0   1         1039  Voc√™ sabia que o menino que mais vai te dar va...      1\n",
      "1   2          213  Hoje com 21 anos, como que por auxilio l√° do a...      1\n",
      "2   3          314  Nesse momento to evitando ela, e ta me dando u...      1\n",
      "3   4          598  Meus sentidos de garota diziam que tinha algum...      1\n",
      "4   5          931  Aquela promessa que eu te fiz naquele natal, e...      1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def processar_arquivo_randomizado():\n",
    "    \"\"\"\n",
    "    Processa o arquivo randomizado aplicando as seguintes transforma√ß√µes:\n",
    "    1. Renomeia a coluna id para id_original\n",
    "    2. Cria novo id sequencial\n",
    "    3. Adiciona coluna de bloco (incremento a cada 150 registros)\n",
    "    \"\"\"\n",
    "    # Encontra o arquivo MQD-*_random_sem_repeticao.csv automaticamente\n",
    "    import glob\n",
    "    arquivos = glob.glob(\"data/logs_processados/MQD-*_random_sem_repeticao.csv\")\n",
    "    \n",
    "    if not arquivos:\n",
    "        raise FileNotFoundError(\"Nenhum arquivo MQD-*_random_sem_repeticao.csv encontrado!\")\n",
    "    \n",
    "    if len(arquivos) > 1:\n",
    "        print(f\"AVISO: M√∫ltiplos arquivos encontrados. Usando o mais recente: {arquivos}\")\n",
    "        # Ordena por tempo de modifica√ß√£o e pega o mais recente\n",
    "        arquivos.sort(key=os.path.getmtime, reverse=True)\n",
    "    \n",
    "    input_path = arquivos[0]\n",
    "    print(f\"Processando arquivo: {input_path}\")\n",
    "    \n",
    "    # Carrega arquivo usando tab como separador e protegendo aspas\n",
    "    df = pd.read_csv(\n",
    "        input_path,\n",
    "        sep='\\t',\n",
    "        usecols=['id', 'frase'],\n",
    "        quoting=csv.QUOTE_ALL,\n",
    "        quotechar='\"',\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "    \n",
    "    # Renomear coluna id para id_original\n",
    "    df = df.rename(columns={'id': 'id_original'})\n",
    "    \n",
    "    # Criar novo id sequencial come√ßando de 1\n",
    "    df.insert(0, 'id', range(1, len(df) + 1))\n",
    "    \n",
    "    # Criar coluna de bloco (incremento a cada 150 registros)\n",
    "    df['bloco'] = (df.index // 150) + 1\n",
    "    \n",
    "    # Define nome do arquivo de saida dinamicamente baseado no numero de registros\n",
    "    num_registros = len(df)\n",
    "    output_path = f\"data/logs_processados/MQD-{num_registros}_blocos.csv\"\n",
    "    \n",
    "    # Salvar novo arquivo mantendo as aspas e usando tab como separador\n",
    "    df.to_csv(\n",
    "        output_path,\n",
    "        sep='\\t',\n",
    "        index=False,\n",
    "        quoting=csv.QUOTE_ALL,\n",
    "        quotechar='\"'\n",
    "    )\n",
    "    \n",
    "    print(f\"Arquivo processado e salvo em: {output_path}\")\n",
    "    print(f\"Total de registros: {len(df)}\")\n",
    "    print(f\"Total de blocos: {df['bloco'].max()}\")\n",
    "    \n",
    "    print(\"\\nPrimeiras linhas do arquivo processado:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Executar processamento\n",
    "df_blocos_randomizados = processar_arquivo_randomizado()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f1fb72",
   "metadata": {},
   "source": [
    "### 2. Tratamento dos logs do PCIbex\n",
    "---\n",
    "* Cria√ß√£o dos blocos concatenados com todas as anota√ß√µes\n",
    "* Tamanho vari√°vel de blocos (anotadores x frases)\n",
    "* Dataset com ParticipantMD5, GeneroCod, frase, Value e duracao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b925697",
   "metadata": {
    "cell_id": "24d4bcb11bd0434dabf8848c384b2e32",
    "deepnote_cell_type": "code",
    "execution_context_id": "1cc7f51c-22a8-4663-972f-e57383e58263",
    "execution_millis": 12227,
    "execution_start": 1748906752360,
    "source_hash": "3d8494b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando arquivo: data/logs_processados\\MQD-1463_blocos.csv\n",
      "\n",
      "Processando bloco 1 - Arquivo: data/logs_brutos/results_prod.csv\n",
      "Frases encontradas no bloco 1: 150\n",
      "Arquivo salvo: data/logs_processados/bloco_1_concatenado.csv\n",
      "Total de classifica√ß√µes: 1350\n",
      "\n",
      "Processando bloco 2 - Arquivo: data/logs_brutos/results_prod (1).csv\n",
      "Frases encontradas no bloco 2: 150\n",
      "Arquivo salvo: data/logs_processados/bloco_2_concatenado.csv\n",
      "Total de classifica√ß√µes: 1200\n",
      "\n",
      "Processando bloco 3 - Arquivo: data/logs_brutos/results_prod (2).csv\n",
      "Frases encontradas no bloco 3: 150\n",
      "Arquivo salvo: data/logs_processados/bloco_3_concatenado.csv\n",
      "Total de classifica√ß√µes: 1800\n",
      "\n",
      "Processando bloco 4 - Arquivo: data/logs_brutos/results_prod (3).csv\n",
      "Frases encontradas no bloco 4: 150\n",
      "Arquivo salvo: data/logs_processados/bloco_4_concatenado.csv\n",
      "Total de classifica√ß√µes: 1200\n",
      "\n",
      "Processando bloco 5 - Arquivo: data/logs_brutos/results_prod (4).csv\n",
      "Frases encontradas no bloco 5: 150\n",
      "Arquivo salvo: data/logs_processados/bloco_5_concatenado.csv\n",
      "Total de classifica√ß√µes: 1350\n",
      "\n",
      "Processando bloco 6 - Arquivo: data/logs_brutos/results_prod (5).csv\n",
      "Frases encontradas no bloco 6: 150\n",
      "Arquivo salvo: data/logs_processados/bloco_6_concatenado.csv\n",
      "Total de classifica√ß√µes: 1200\n",
      "\n",
      "Processando bloco 7 - Arquivo: data/logs_brutos/results_prod (6).csv\n",
      "Frases encontradas no bloco 7: 150\n",
      "Arquivo salvo: data/logs_processados/bloco_7_concatenado.csv\n",
      "Total de classifica√ß√µes: 1350\n",
      "\n",
      "Processando bloco 8 - Arquivo: data/logs_brutos/results_prod (7).csv\n",
      "Frases encontradas no bloco 8: 150\n",
      "Arquivo salvo: data/logs_processados/bloco_8_concatenado.csv\n",
      "Total de classifica√ß√µes: 1500\n",
      "\n",
      "Processando bloco 9 - Arquivo: data/logs_brutos/results_prod (8).csv\n",
      "Frases encontradas no bloco 9: 150\n",
      "Arquivo salvo: data/logs_processados/bloco_9_concatenado.csv\n",
      "Total de classifica√ß√µes: 1350\n",
      "\n",
      "Processando bloco 10 - Arquivo: data/logs_brutos/results_prod (9).csv\n",
      "Frases encontradas no bloco 10: 113\n",
      "Arquivo salvo: data/logs_processados/bloco_10_concatenado.csv\n",
      "Total de classifica√ß√µes: 1017\n"
     ]
    }
   ],
   "source": [
    "def carregar_blocos_randomizados():\n",
    "    \"\"\"\n",
    "    Carrega o arquivo com as frases e seus respectivos blocos\n",
    "    \"\"\"\n",
    "    # Encontra o arquivo MQD-*_blocos.csv automaticamente\n",
    "    import glob\n",
    "    arquivos = glob.glob(\"data/logs_processados/MQD-*_blocos.csv\")\n",
    "    \n",
    "    if not arquivos:\n",
    "        raise FileNotFoundError(\"Nenhum arquivo MQD-*_blocos.csv encontrado!\")\n",
    "    \n",
    "    if len(arquivos) > 1:\n",
    "        # Ordena por tempo de modifica√ß√£o e pega o mais recente\n",
    "        arquivos.sort(key=os.path.getmtime, reverse=True)\n",
    "    \n",
    "    blocos_path = arquivos[0]\n",
    "    print(f\"Carregando arquivo: {blocos_path}\")\n",
    "    \n",
    "    return pd.read_csv(\n",
    "        blocos_path,\n",
    "        sep='\\t',\n",
    "        quoting=csv.QUOTE_ALL,\n",
    "        quotechar='\"',\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "\n",
    "def extrair_genero(df):\n",
    "    \"\"\"\n",
    "    Extrai o g√™nero dos participantes do arquivo de log\n",
    "    \"\"\"\n",
    "    genero_data = df[\n",
    "        (df[\"Label\"] == \"genero\") &\n",
    "        (df[\"PennElementName\"] == \"selecionaGenero\") &\n",
    "        (df[\"Parameter\"] == \"Selected\")\n",
    "    ][[\"ParticipantMD5\", \"Value\"]].copy()\n",
    "    \n",
    "    genero_data[\"GeneroCod\"] = genero_data[\"Value\"].str.lower().map(\n",
    "        lambda g: \"m\" if \"masculino\" in g else \"f\"\n",
    "    )\n",
    "    \n",
    "    return genero_data[[\"ParticipantMD5\", \"GeneroCod\"]]\n",
    "\n",
    "def processar_arquivo_log(file_path, frases_bloco, num_bloco):\n",
    "    \"\"\"\n",
    "    Processa um arquivo de log substituindo as frases originais pelas do bloco correto\n",
    "    e calcula a dura√ß√£o dos trials\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # L√™ o arquivo de log pulando as 19 linhas de cabe√ßalho\n",
    "        df = pd.read_csv(file_path, skiprows=19, header=None)\n",
    "        \n",
    "        # Define as colunas apenas uma vez\n",
    "        df.columns = [\n",
    "            \"ReceptionTime\", \"ParticipantMD5\", \"Controller\", \"ItemNumber\", \n",
    "            \"InnerElementNumber\", \"Label\", \"Group\", \"PennElementType\", \n",
    "            \"PennElementName\", \"Parameter\", \"Value\", \"EventTime\", \"Comments\"\n",
    "        ]\n",
    "        \n",
    "        # Converte EventTime para num√©rico\n",
    "        df[\"EventTime\"] = pd.to_numeric(df[\"EventTime\"], errors=\"coerce\")\n",
    "        \n",
    "        # Extrai informa√ß√µes de g√™nero\n",
    "        generos = extrair_genero(df)\n",
    "        \n",
    "        # Filtra eventos de in√≠cio e fim dos trials\n",
    "        df_trials = df[\n",
    "            (df[\"Label\"] == \"frases\") & \n",
    "            (df[\"Value\"].isin([\"Start\", \"End\"]))\n",
    "        ].copy()\n",
    "        \n",
    "        # Ordena por participante, item e tempo\n",
    "        df_trials = df_trials.sort_values([\"ParticipantMD5\", \"ItemNumber\", \"EventTime\"])\n",
    "        \n",
    "        # Calcula dura√ß√£o entre Start e End para cada trial\n",
    "        duracoes = []\n",
    "        for (participant, item), group in df_trials.groupby([\"ParticipantMD5\", \"ItemNumber\"]):\n",
    "            if len(group) == 2:  # Verifica se tem tanto Start quanto End\n",
    "                start_time = group[group[\"Value\"] == \"Start\"][\"EventTime\"].iloc[0]\n",
    "                end_time = group[group[\"Value\"] == \"End\"][\"EventTime\"].iloc[0]\n",
    "                duracao = (end_time - start_time) / 1000.0  # Converte para segundos\n",
    "                \n",
    "                # Ajusta o ItemNumber da mesma forma que √© feito para as classifica√ß√µes\n",
    "                adjusted_item = item - 3 if num_bloco == 1 else item - 3 + ((num_bloco - 1) * 150)\n",
    "                \n",
    "                duracoes.append({\n",
    "                    \"ParticipantMD5\": participant,\n",
    "                    \"ItemNumber\": adjusted_item,\n",
    "                    \"duracao\": duracao\n",
    "                })\n",
    "        \n",
    "        df_duracoes = pd.DataFrame(duracoes)\n",
    "        \n",
    "        # Filtra apenas as linhas de classifica√ß√£o\n",
    "        df_classificacoes = df[\n",
    "            (df[\"Label\"] == \"frases\") & \n",
    "            (df[\"Parameter\"] == \"Selection\")\n",
    "        ].copy()\n",
    "        \n",
    "        # Ajusta o ItemNumber baseado no n√∫mero do bloco\n",
    "        if num_bloco == 1:\n",
    "            df_classificacoes[\"ItemNumber\"] = df_classificacoes[\"ItemNumber\"] - 3\n",
    "        else:\n",
    "            df_classificacoes[\"ItemNumber\"] = df_classificacoes[\"ItemNumber\"] - 3 + ((num_bloco - 1) * 150)\n",
    "        \n",
    "        # Merge com as frases do bloco\n",
    "        df_final = df_classificacoes.merge(\n",
    "            frases_bloco[[\"id\", \"frase\"]],\n",
    "            left_on=\"ItemNumber\",\n",
    "            right_on=\"id\",\n",
    "            how=\"inner\"\n",
    "        )\n",
    "        \n",
    "        # Adiciona informa√ß√£o de g√™nero\n",
    "        df_final = df_final.merge(\n",
    "            generos,\n",
    "            on=\"ParticipantMD5\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "        \n",
    "        # Adiciona informa√ß√£o de dura√ß√£o\n",
    "        df_final = df_final.merge(\n",
    "            df_duracoes,\n",
    "            on=[\"ParticipantMD5\", \"ItemNumber\"],\n",
    "            how=\"left\"\n",
    "        )\n",
    "        \n",
    "        return df_final[[\"ParticipantMD5\", \"GeneroCod\", \"frase\", \"Value\", \"duracao\"]]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar arquivo: {str(e)}\")\n",
    "        print(f\"Local do erro: {e.__traceback__.tb_lineno}\")\n",
    "        raise\n",
    "def processar_todos_arquivos():\n",
    "    \"\"\"\n",
    "    Processa todos os arquivos de log, correlacionando com os blocos corretos\n",
    "    \"\"\"\n",
    "    #pasta_destino = criar_pasta_tratamento()\n",
    "    pasta_destino = \"data/logs_processados\"\n",
    "    os.makedirs(pasta_destino, exist_ok=True)\n",
    "    df_blocos = carregar_blocos_randomizados()\n",
    "    \n",
    "    # Para cada arquivo de log (0 a 9)\n",
    "    for i in range(10):\n",
    "        num_bloco = i + 1\n",
    "        if i == 0:\n",
    "            arquivo_origem = \"data/logs_brutos/results_prod.csv\"\n",
    "        else:\n",
    "            arquivo_origem = f\"data/logs_brutos/results_prod ({i}).csv\"\n",
    "            \n",
    "        arquivo_destino = f\"{pasta_destino}/bloco_{num_bloco}_concatenado.csv\"\n",
    "        \n",
    "        if os.path.exists(arquivo_origem):\n",
    "            print(f\"\\nProcessando bloco {num_bloco} - Arquivo: {arquivo_origem}\")\n",
    "            \n",
    "            frases_bloco = df_blocos[df_blocos['bloco'] == num_bloco].copy()\n",
    "            print(f\"Frases encontradas no bloco {num_bloco}: {len(frases_bloco)}\")\n",
    "            \n",
    "            try:\n",
    "                df_processado = processar_arquivo_log(arquivo_origem, frases_bloco, num_bloco)\n",
    "                \n",
    "                if len(df_processado) > 0:\n",
    "                    df_processado.to_csv(\n",
    "                        arquivo_destino,\n",
    "                        sep='\\t',\n",
    "                        index=False,\n",
    "                        quoting=csv.QUOTE_ALL,\n",
    "                        quotechar='\"',\n",
    "                        encoding='utf-8',\n",
    "                        float_format='%.3f'  # Format float numbers with 3 decimal places\n",
    "                    )\n",
    "                    print(f\"Arquivo salvo: {arquivo_destino}\")\n",
    "                    print(f\"Total de classifica√ß√µes: {len(df_processado)}\")\n",
    "                else:\n",
    "                    print(f\"AVISO: Nenhuma classifica√ß√£o encontrada para o bloco {num_bloco}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar bloco {num_bloco}: {str(e)}\")\n",
    "        else:\n",
    "            print(f\"Arquivo n√£o encontrado: {arquivo_origem}\")\n",
    "\n",
    "# Executa o processamento\n",
    "processar_todos_arquivos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf0dfb3",
   "metadata": {
    "cell_id": "f16cbf2fd16b4fe68f345d2d1f1cbf05",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96d72615",
   "metadata": {
    "cell_id": "1a611baf5d324a6590ebb8ffff051491",
    "deepnote_cell_type": "code",
    "execution_context_id": "8fccc835-d101-40f7-b801-a63fb16404c7",
    "execution_millis": 4241,
    "execution_start": 1748906791341,
    "source_hash": "97063f63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo criado com sucesso em: data\\logs_processados\\MQD-13317_anotacoes_totais.csv\n",
      "Total de registros: 13317\n"
     ]
    }
   ],
   "source": [
    "# Criacao do dataset com todas as anota√ßoes\n",
    "\n",
    "# Define o caminho da pasta\n",
    "logs_path = Path('data/logs_processados')\n",
    "\n",
    "# Lista todos os arquivos de bloco concatenados\n",
    "bloco_files = list(logs_path.glob('bloco_*_concatenado.csv'))\n",
    "\n",
    "# Cria uma lista para armazenar os DataFrames\n",
    "dfs = []\n",
    "\n",
    "# L√™ cada arquivo mantendo a estrutura original\n",
    "for file in bloco_files:\n",
    "    df = pd.read_csv(file, sep='\\t')  # Remove a defini√ß√£o manual de colunas\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatena todos os DataFrames\n",
    "df_totais_com_duracao = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Remove duplicatas se houver\n",
    "#df_totais_com_duracao = df_totais_com_duracao.drop_duplicates()\n",
    "\n",
    "# Salva o DataFrame consolidado mantendo o formato original\n",
    "output_file = logs_path / 'MQD-13317_anotacoes_totais.csv'\n",
    "df_totais_com_duracao.to_csv(output_file, sep='\\t', index=False)  # Adiciona sep='\\t'\n",
    "\n",
    "print(f\"Arquivo criado com sucesso em: {output_file}\")\n",
    "print(f\"Total de registros: {len(df_totais_com_duracao)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e058e02e",
   "metadata": {
    "cell_id": "414b2ae275d841e295dcfc3b62822967",
    "deepnote_cell_type": "code",
    "execution_context_id": "8fccc835-d101-40f7-b801-a63fb16404c7",
    "execution_millis": 571,
    "execution_start": 1748906795640,
    "source_hash": "9785b6d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset masculino salvo em: data\\logs_processados\\MQD-7015_anotacoes_totais_masculinas.csv\n",
      "Total de registros masculinos: 7015\n",
      "\n",
      "Dataset feminino salvo em: data\\logs_processados\\MQD-6302_anotacoes_totais_femininas.csv\n",
      "Total de registros femininos: 6302\n"
     ]
    }
   ],
   "source": [
    "# Separa por g√™nero\n",
    "\n",
    "# L√™ o arquivo original\n",
    "df = pd.read_csv('data/logs_processados/MQD-13317_anotacoes_totais.csv', sep='\\t')\n",
    "\n",
    "# Separa por g√™nero\n",
    "df_totais_masculinos = df[df['GeneroCod'] == 'm']\n",
    "df_totais_femininos = df[df['GeneroCod'] == 'f']\n",
    "\n",
    "# Salva os arquivos separados\n",
    "output_masculino = logs_path / 'MQD-7015_anotacoes_totais_masculinas.csv'\n",
    "output_feminino = logs_path / 'MQD-6302_anotacoes_totais_femininas.csv'\n",
    "\n",
    "df_totais_masculinos.to_csv(output_masculino, sep='\\t', index=False)\n",
    "df_totais_femininos.to_csv(output_feminino, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Dataset masculino salvo em: {output_masculino}\")\n",
    "print(f\"Total de registros masculinos: {len(df_totais_masculinos)}\")\n",
    "print(f\"\\nDataset feminino salvo em: {output_feminino}\")\n",
    "print(f\"Total de registros femininos: {len(df_totais_femininos)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de20f83",
   "metadata": {},
   "source": [
    "## Gera√ß√£o do Dataset Final: 4 Classifica√ß√µes com Maioria Estrita\n",
    "\n",
    "Esta se√ß√£o gera o dataset final garantindo:\n",
    "1. **Exatamente 4 classifica√ß√µes** por g√™nero para cada frase\n",
    "2. **Maioria estrita** definida (sem empate 2-2)\n",
    "3. **Paridade** entre g√™neros (apenas frases presentes em ambos)\n",
    "\n",
    "**L√≥gica de sele√ß√£o:**\n",
    "- Usar as 4 primeiras anota√ß√µes (ordem temporal)\n",
    "- Se houver empate 2-2, substituir √∫ltima anota√ß√£o por pr√≥xima dispon√≠vel\n",
    "- Se imposs√≠vel resolver empate, descartar a frase\n",
    "\n",
    "**Maioria estrita v√°lida:**\n",
    "- ‚úì 4-0-0 (unanimidade)\n",
    "- ‚úì 3-1-0 \n",
    "- ‚úì 2-1-1 (uma classe √† frente)\n",
    "- ‚úó 2-2-0 (empate - descartada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85833f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GERA√á√ÉO DO DATASET FINAL\n",
      "================================================================================\n",
      "Anota√ß√µes masculinas: 7015\n",
      "Anota√ß√µes femininas: 6302\n",
      "\n",
      "[1] Processando anota√ß√µes masculinas...\n",
      "    ‚úì 1388 frases com maioria estrita\n",
      "    ‚úó 75 frases descartadas (empate irresolv√≠vel)\n",
      "\n",
      "[2] Processando anota√ß√µes femininas...\n",
      "    ‚úì 1263 frases com maioria estrita\n",
      "    ‚úó 200 frases descartadas (empate irresolv√≠vel)\n",
      "\n",
      "[3] Combinando datasets...\n",
      "    ‚úì 1209 frases em comum (ambos g√™neros com maioria estrita)\n",
      "\n",
      "[4] Concord√¢ncia entre grupos:\n",
      "    Concordam: 1021 (84.4%)\n",
      "    Discordam: 188 (15.6%)\n",
      "\n",
      "[5] Arquivo salvo: MQD-1209_majoritarias.csv\n",
      "\n",
      "================================================================================\n",
      "ESTAT√çSTICAS DO DATASET FINAL\n",
      "================================================================================\n",
      "\n",
      "Distribui√ß√£o de votos na maioria:\n",
      "\n",
      "Masculino:\n",
      "votos_maioria_masculino\n",
      "2    129\n",
      "3    460\n",
      "4    620\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Feminino:\n",
      "votos_maioria_feminino\n",
      "2    115\n",
      "3    598\n",
      "4    496\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribui√ß√£o de classes majorit√°rias:\n",
      "\n",
      "Masculino:\n",
      "classificacao_majoritaria_masculino\n",
      "positiva    475\n",
      "negativa    444\n",
      "neutra      290\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Feminino:\n",
      "classificacao_majoritaria_feminino\n",
      "negativa    440\n",
      "positiva    406\n",
      "neutra      363\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "‚úì DATASET FINAL GERADO COM SUCESSO\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# GERA√á√ÉO DO DATASET FINAL: 4 CLASSIFICA√á√ïES COM MAIORIA ESTRITA\n",
    "# =============================================================================\n",
    "\n",
    "# Carregar dados brutos de anota√ß√µes individuais\n",
    "df_masc_raw = pd.read_csv(logs_path / 'MQD-7015_anotacoes_totais_masculinas.csv', sep='\\t')\n",
    "df_fem_raw = pd.read_csv(logs_path / 'MQD-6302_anotacoes_totais_femininas.csv', sep='\\t')\n",
    "\n",
    "# Adicionar √≠ndice original para preservar ordem temporal\n",
    "df_masc_raw['ordem_original'] = df_masc_raw.index\n",
    "df_fem_raw['ordem_original'] = df_fem_raw.index\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GERA√á√ÉO DO DATASET FINAL\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Anota√ß√µes masculinas: {len(df_masc_raw)}\")\n",
    "print(f\"Anota√ß√µes femininas: {len(df_fem_raw)}\")\n",
    "\n",
    "\n",
    "def tem_maioria_estrita(contagem):\n",
    "    \"\"\"\n",
    "    Verifica se h√° maioria estrita (sem empate no topo).\n",
    "    \n",
    "    Maioria estrita = UMA classe com mais votos que qualquer outra.\n",
    "    - 4-0-0: ‚úì (unanimidade)\n",
    "    - 3-1-0: ‚úì \n",
    "    - 2-1-1: ‚úì (uma classe √† frente)\n",
    "    - 2-2-0: ‚úó (empate)\n",
    "    \"\"\"\n",
    "    valores = sorted(contagem.values, reverse=True)\n",
    "    if len(valores) >= 2 and valores[0] == valores[1]:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def selecionar_4_com_maioria(grupo):\n",
    "    \"\"\"\n",
    "    Seleciona exatamente 4 anota√ß√µes que garantam maioria estrita.\n",
    "    \n",
    "    Estrat√©gia:\n",
    "    1. Ordenar por ordem temporal\n",
    "    2. Tentar com as 4 primeiras\n",
    "    3. Se empate (2-2), substituir √∫ltima por pr√≥xima dispon√≠vel\n",
    "    \"\"\"\n",
    "    grupo = grupo.sort_values('ordem_original').reset_index(drop=True)\n",
    "    n = len(grupo)\n",
    "    \n",
    "    if n < 4:\n",
    "        return None\n",
    "    \n",
    "    # Tentar com as 4 primeiras\n",
    "    primeiras_4 = grupo.head(4)\n",
    "    contagem = primeiras_4['Value'].value_counts()\n",
    "    \n",
    "    if tem_maioria_estrita(contagem):\n",
    "        return primeiras_4\n",
    "    \n",
    "    # Se tem empate e mais anota√ß√µes, tentar substitui√ß√µes\n",
    "    if n > 4:\n",
    "        for i in range(4, n):\n",
    "            candidatos_idx = [0, 1, 2, i]\n",
    "            selecao = grupo.iloc[candidatos_idx]\n",
    "            contagem = selecao['Value'].value_counts()\n",
    "            if tem_maioria_estrita(contagem):\n",
    "                return selecao\n",
    "        \n",
    "        for i in range(4, n):\n",
    "            candidatos_idx = [0, 1, i, 3]\n",
    "            selecao = grupo.iloc[candidatos_idx]\n",
    "            contagem = selecao['Value'].value_counts()\n",
    "            if tem_maioria_estrita(contagem):\n",
    "                return selecao\n",
    "        \n",
    "        for i in range(4, n):\n",
    "            for j in range(i+1, n) if n > i+1 else []:\n",
    "                candidatos_idx = [0, 1, i, j]\n",
    "                selecao = grupo.iloc[candidatos_idx]\n",
    "                contagem = selecao['Value'].value_counts()\n",
    "                if tem_maioria_estrita(contagem):\n",
    "                    return selecao\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def processar_grupo(df, genero):\n",
    "    \"\"\"Processa todas as frases de um g√™nero.\"\"\"\n",
    "    resultados = []\n",
    "    descartadas = []\n",
    "    \n",
    "    for frase in df['frase'].unique():\n",
    "        grupo = df[df['frase'] == frase]\n",
    "        selecao = selecionar_4_com_maioria(grupo)\n",
    "        \n",
    "        if selecao is not None:\n",
    "            contagem = selecao['Value'].value_counts()\n",
    "            maioria = contagem.idxmax()\n",
    "            votos_maioria = contagem.max()\n",
    "            \n",
    "            votos_positiva = (selecao['Value'] == 'positiva').sum()\n",
    "            votos_negativa = (selecao['Value'] == 'negativa').sum()\n",
    "            votos_neutra = (selecao['Value'] == 'neutra').sum()\n",
    "            duracao_media = selecao['duracao'].mean()\n",
    "            \n",
    "            resultados.append({\n",
    "                'frase': frase,\n",
    "                f'total_classificacoes_{genero}': 4,\n",
    "                f'classificacao_majoritaria_{genero}': maioria,\n",
    "                f'votos_maioria_{genero}': votos_maioria,\n",
    "                f'total_positiva_{genero}': votos_positiva,\n",
    "                f'total_negativa_{genero}': votos_negativa,\n",
    "                f'total_neutra_{genero}': votos_neutra,\n",
    "                f'duracao_media_{genero}': duracao_media\n",
    "            })\n",
    "        else:\n",
    "            descartadas.append(frase)\n",
    "    \n",
    "    return pd.DataFrame(resultados), descartadas\n",
    "\n",
    "\n",
    "# Processar cada g√™nero\n",
    "print(\"\\n[1] Processando anota√ß√µes masculinas...\")\n",
    "df_result_masc, descartadas_masc = processar_grupo(df_masc_raw, 'masculino')\n",
    "print(f\"    ‚úì {len(df_result_masc)} frases com maioria estrita\")\n",
    "print(f\"    ‚úó {len(descartadas_masc)} frases descartadas (empate irresolv√≠vel)\")\n",
    "\n",
    "print(\"\\n[2] Processando anota√ß√µes femininas...\")\n",
    "df_result_fem, descartadas_fem = processar_grupo(df_fem_raw, 'feminino')\n",
    "print(f\"    ‚úì {len(df_result_fem)} frases com maioria estrita\")\n",
    "print(f\"    ‚úó {len(descartadas_fem)} frases descartadas (empate irresolv√≠vel)\")\n",
    "\n",
    "# Combinar (inner join - apenas frases em comum)\n",
    "print(\"\\n[3] Combinando datasets...\")\n",
    "df_final = df_result_masc.merge(df_result_fem, on='frase', how='inner')\n",
    "print(f\"    ‚úì {len(df_final)} frases em comum (ambos g√™neros com maioria estrita)\")\n",
    "\n",
    "# Calcular concord√¢ncia entre grupos\n",
    "df_final['concordancia_grupos'] = (\n",
    "    df_final['classificacao_majoritaria_masculino'] == \n",
    "    df_final['classificacao_majoritaria_feminino']\n",
    ").astype(int)\n",
    "\n",
    "n_concordam = df_final['concordancia_grupos'].sum()\n",
    "n_discordam = len(df_final) - n_concordam\n",
    "\n",
    "print(f\"\\n[4] Concord√¢ncia entre grupos:\")\n",
    "print(f\"    Concordam: {n_concordam} ({100*n_concordam/len(df_final):.1f}%)\")\n",
    "print(f\"    Discordam: {n_discordam} ({100*n_discordam/len(df_final):.1f}%)\")\n",
    "\n",
    "# Ordenar colunas\n",
    "colunas_ordem = [\n",
    "    'frase',\n",
    "    'duracao_media_masculino', 'total_classificacoes_masculino',\n",
    "    'classificacao_majoritaria_masculino', 'votos_maioria_masculino',\n",
    "    'total_positiva_masculino', 'total_negativa_masculino', 'total_neutra_masculino',\n",
    "    'duracao_media_feminino', 'total_classificacoes_feminino',\n",
    "    'classificacao_majoritaria_feminino', 'votos_maioria_feminino',\n",
    "    'total_positiva_feminino', 'total_negativa_feminino', 'total_neutra_feminino',\n",
    "    'concordancia_grupos'\n",
    "]\n",
    "df_final = df_final[colunas_ordem]\n",
    "\n",
    "# Salvar\n",
    "output_file = logs_path / f'MQD-{len(df_final)}_majoritarias.csv'\n",
    "df_final.to_csv(output_file, sep='\\t', index=False)\n",
    "print(f\"\\n[5] Arquivo salvo: {output_file.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ESTAT√çSTICAS DO DATASET FINAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nDistribui√ß√£o de votos na maioria:\")\n",
    "print(\"\\nMasculino:\")\n",
    "print(df_final['votos_maioria_masculino'].value_counts().sort_index())\n",
    "print(\"\\nFeminino:\")\n",
    "print(df_final['votos_maioria_feminino'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nDistribui√ß√£o de classes majorit√°rias:\")\n",
    "print(\"\\nMasculino:\")\n",
    "print(df_final['classificacao_majoritaria_masculino'].value_counts())\n",
    "print(\"\\nFeminino:\")\n",
    "print(df_final['classificacao_majoritaria_feminino'].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úì DATASET FINAL GERADO COM SUCESSO\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
